{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Project 1: Retrieving materials from a website\n",
    "Often, people need to download many documents on a webpage. For example, the CS 229 Machine Learning course provided by Stanford has many good materials on the website ((http://cs229.stanford.edu/materials.html). For someone like me who wants to download the materials first and digest them later, the many links that need to be manually clicked one by one are really scary if we don’t have an automatic file-downloading tool. Such tools are available and one example can be Xunlei, but from a programmer’s perspective, it would be interesting and handy to be able to download files from a webpage by running a small and simple script. A sample Python script that I found from somewhere else and modified is provided below, and you can easily change the script for your own needs. Enjoy and have fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "BASE_URL = \"http://cs229.stanford.edu/\"\n",
    "r = requests.get(BASE_URL)\n",
    "soup = BeautifulSoup(r.content, \"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MATERIALS_URL = [BASE_URL + item[\"href\"] for item in soup.find_all('a') if item[\"href\"].endswith('materials.html')][0]\n",
    "PROJECTS_URL = [BASE_URL + item[\"href\"] for item in soup.find_all('a') if item[\"href\"][:8] == 'projects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "r2 = requests.get(MATERIALS_URL)\n",
    "soup2 = BeautifulSoup(r2.content, \"html5lib\")\n",
    "urls2 = [item[\"href\"] if item[\"href\"].startswith(\"http:\") else BASE_URL + item[\"href\"] for item in soup2.find_all('a')]\n",
    "r3 = [requests.get(purl) for purl in PROJECTS_URL]\n",
    "soup3 = [BeautifulSoup(i.content, \"html5lib\") for i in r3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.stanford.edu/class/cs229/\n",
      "http://cs229.stanford.edu/info.html\n",
      "http://cs229.stanford.edu/schedule.html\n",
      "http://cs229.stanford.edu/materials/ps0.pdf\n",
      "http://cs229.stanford.edu/materials/ps0.pdf\n",
      "ps0.pdf\n"
     ]
    }
   ],
   "source": [
    "for item in urls2:\n",
    "    filename = item.split('/')[-1]\n",
    "    if \"pdf\" in filename or \"dat\" in filename or \"zip\" in filename:  \n",
    "        urllib.request.urlretrieve(item, filename)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Conclusions**: This has concluded the usage of requests and urllib to download materials from a webiste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    }
   ],
   "source": [
    "print(\"The End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Project 1; extract data from EIA [website](https://www.eia.gov/petroleum/drilling/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "BASE_URL = \"https://www.eia.gov/petroleum/drilling/\"\n",
    "r = requests.get(BASE_URL)\n",
    "soup = BeautifulSoup(r.content, \"html5lib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Project 2: download data from Twitter API\n",
    "### Project 3: download data from Amazon API\n",
    "### Project 4: download data from YouTube API\n",
    "### Project 5: download data from Facebook API\n",
    "### Project 6: download data from other APIs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0a1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
